<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera App</title>
    <style>
        body {
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        #response-box {
            margin-top: 20px;
            padding: 10px;
            border: 2px solid #4CAF50;
            border-radius: 5px;
            width: 100%;
            max-width: 640px;
            box-sizing: border-box;
            overflow-wrap: break-word;
        }
        #preview-image, #captured-photo {
            max-width: 100%;
            height: auto;
        }
    </style>
</head>
<body>

    <canvas id="camera-feed"></canvas>

    <div id="response-box">
        <h2>Server Response</h2>
        <img id="preview-image" alt="Server Response">
    </div>

    <script>
        const videoCanvas = document.getElementById('camera-feed');
        const previewImage = document.getElementById('preview-image');
        let videoStream;
        let capturedFrameBlob;

        // Access the camera and display the video feed
        async function startCamera() {
            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(device => device.kind === 'videoinput');
                const facingMode = 'environment'; // Set to 'environment' for the back camera

                const constraints = {
                    video: { facingMode },
                };

                videoStream = await navigator.mediaDevices.getUserMedia(constraints);

                const videoElement = document.createElement('video');
                videoElement.srcObject = videoStream;
                videoElement.addEventListener('loadedmetadata', () => {
                    const { videoWidth, videoHeight } = videoElement;
                    videoCanvas.width = videoWidth;
                    videoCanvas.height = videoHeight;
                    drawVideoFrame(videoElement, videoCanvas.getContext('2d'));
                });
                videoElement.play();
            } catch (error) {
                console.error('Error accessing camera:', error);
            }
        }

        // Function to draw the video frame on the canvas
        function drawVideoFrame(video, context) {
            context.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);

            // Draw a square on the canvas
            const squareSizeMM = 300;
            const squareSizePixels = squareSizeMM * (videoCanvas.width / 640); // Adjust based on max-width
            const squareColor = 'green';
            const x = (videoCanvas.width - squareSizePixels) / 2;
            const y = (videoCanvas.height - squareSizePixels) / 2;

            context.strokeStyle = squareColor;
            context.lineWidth = 2;
            context.strokeRect(x, y, squareSizePixels, squareSizePixels);

            requestAnimationFrame(() => drawVideoFrame(video, context));
        }

        // Function to capture a photo
        async function capturePhoto() {
            if (videoStream) {
                // Pause the video feed
                videoStream.getTracks().forEach(track => track.stop());

                // Draw the captured frame on the photo canvas
                const capturedFrameCanvas = document.createElement('canvas');
                capturedFrameCanvas.width = videoCanvas.width;
                capturedFrameCanvas.height = videoCanvas.height;
                const capturedFrameContext = capturedFrameCanvas.getContext('2d');
                capturedFrameContext.drawImage(videoCanvas, 0, 0, videoCanvas.width, videoCanvas.height);

                // Convert the captured frame to a Blob with JPG format
                capturedFrameBlob = await new Promise(resolve => capturedFrameCanvas.toBlob(resolve, 'image/jpeg'));

                // Display the captured photo in the preview
                const imageUrl = URL.createObjectURL(capturedFrameBlob);
                previewImage.src = imageUrl;
            }
        }

        // Start the camera when the page loads
        document.addEventListener('DOMContentLoaded', startCamera);
    </script>

    <button onclick="capturePhoto()">Take Photo</button>
</body>
</html>
